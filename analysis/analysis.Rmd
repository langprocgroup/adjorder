---
title: "Adjective Order Analysis"
author: "Richard Futrell, William Dyer, & Greg Scontras"
date: "11/27/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(plotrix)
library(tidyverse)
library(stringr)
library(ROCR)

STRICT_INCLUSION = T

```

## Load data

```{r}
train_scores = read_csv("../cc_aan_scores.csv", na=c("None"))
ud_test_scores = read_csv("../ud_aan_scores.csv", na=c("None"))
cc_test_scores = read_csv("../cc_aan_test_scores.csv", na=c("None"))
```


## Some useful functions
```{r}

PREDICTORS = c(
"p_awf","p_acl","p_nwf","p_ncl","p_awf_nwf","p_awf_ncl","p_acl_nwf","p_acl_ncl","ic_awf_nwf","ic_awf_ncl","ic_acl_nwf","ic_acl_ncl","pmi_awf_nwf","pmi_awf_ncl","pmi_acl_nwf","pmi_acl_ncl","s_awf","s_acl","ig_awf_nwf","ig_awf_ncl","ig_acl_nwf","ig_acl_ncl"
)

get_deltas = function(d) {
  # Given scores, return the difference in scores for the first adjective minus the second adjective, for all predictors
  d %>% 
    select(-awf, -nwf, -acl, -ncl) %>%
    gather(predictor, value, -id, -idx, -count) %>%
    spread(idx, value) %>%
    mutate(delta=`0` - `1`) %>%
    select(-`0`, -`1`) %>%
    spread(predictor, delta)
}

accuracy = function(m, d) {
  # Accuracy of a model m for predicting data d, along with standard error and 95% confidence intervals according to the Normal approximation to the Binomial confidence interval
  d %>% 
    mutate(predicted = predict(m, d) > .5,
           correct = predicted == alphabetical) %>%
    summarise(
      m=mean(correct, na.rm=T),
      se=std.error(correct, na.rm=T),
      upper=m+1.96*se,
      lower=m-1.96*se,
      n=sum(!is.na(correct))
    )
}

```


## Data manipulation
```{r}

replicate_row = function(r,n) {
    r[rep(1:nrow(r),n),1:ncol(r)]
}

unroll = function(d) {
    replicate_row(d, d$count)
}

regression_format_data = function(scores) {

  indices = scores %>%
    select(id, idx, count, awf, nwf) %>%
    unite(anwf, awf, nwf) %>%
    spread(idx, anwf) %>%
    rename(a1=`0`, a2=`1`) %>%
    separate(a1, into=c("a1", "n")) %>%
    separate(a2, into=c("a2", "n2")) %>%
    select(-n2) %>%
    select(id, count, a1, a2, n) %>%
    mutate(alphabetical = a1 < a2)

  scores %>%
    get_deltas() %>%
    inner_join(indices) %>%
    gather(predictor, value, -id, -count, -a1, -a2, -n, -alphabetical) %>%
    group_by(id) %>%
      mutate(any_na=any(is.na(value))) %>%
      ungroup() %>%
    filter(!STRICT_INCLUSION | !any_na) %>%
    mutate(value=if_else(alphabetical, value, -value)) %>%
    spread(predictor, value) %>%
    unroll() %>%
    select(-count)
  
}

train_d = regression_format_data(train_scores)
ud_test_d = regression_format_data(ud_test_scores)
cc_test_d = regression_format_data(cc_test_scores)

```

## Fit regressions
```{r}

plusify = function(xs) {
  str_c(xs, collapse=" + ")
}

fit_model_from_predictors = function(predictors, data) {
    formula = as.formula(str_c("alphabetical ~ ", plusify(predictors)))
    glm(formula, data=data)
}

fit_models = function(predictors, data) {
  map(predictors, function(p) {fit_model_from_predictors(p, data)})
}

get_predictions = function(predictors, train_data, test_data) {
  model = fit_model_from_predictors(predictors, train_data)
  predict(model, test_data) > .5

}

get_corrects = function(predictors, train_data, test_data) {
  get_predictions(predictors, train_data, test_data) == test_data$alphabetical
}



```

## Summarize accuracies

```{r}
get_accuracy_table = function(predictors, train_data, test_data) {
  predictors %>%
    fit_models(train_data) %>%
    map(function(m) {accuracy(m, test_data)}) %>%
    reduce(bind_rows) %>%
    mutate(predictors=as.character(map(predictors, plusify)))
}

VS_SUBJECTIVITY_WF = list(
  c("s_awf", "pmi_awf_nwf"),
  c("s_awf", "pmi_awf_ncl"),
  c("s_awf", "pmi_acl_nwf"),
  c("s_awf", "pmi_acl_ncl"),
  c("s_awf", "ic_awf_nwf"),
  c("s_awf", "ic_awf_ncl"),
  c("s_awf", "ic_acl_nwf"),
  c("s_awf", "ic_acl_ncl"),
  c("s_awf", "ig_awf_nwf"),
  c("s_awf", "ig_awf_ncl"),
  c("s_awf", "ig_acl_nwf"),
  c("s_awf", "ig_acl_ncl")
)

THREE = list(
  c("pmi_awf_nwf", "s_awf", "ig_acl_ncl"),
  c("pmi_awf_nwf", "s_awf", "ic_acl_ncl")
)

VS_SUBJECTIVITY_CL = list(
  c("s_acl", "pmi_acl_ncl"),
  c("s_acl", "ic_acl_ncl"),
  c("s_acl", "ig_acl_ncl")
)

```

```{r}
get_accuracy_table(PREDICTORS, train_d, ud_test_d) %>% arrange(-m)
```

```{r}

plot_accuracies = function(predictors, train_d, test_d) {

acc = get_accuracy_table(predictors, train_d, test_d) %>% 
  separate(predictors, sep="_", into=c("predictor", "source_a", "source_n")) %>% 
  filter(predictor != "p")

acc1 = acc %>% 
  filter(is.na(source_n)) %>%
  mutate(source_n=if_else(is.na(source_n), "nwf", source_n)) 

acc2 = acc %>% 
  filter(is.na(source_n)) %>%
  mutate(source_n=if_else(is.na(source_n), "ncl", source_n))

acc = acc %>% filter(!is.na(source_n)) %>% rbind(acc1) %>% rbind(acc2)

acc %>%
  mutate(predictor=if_else(predictor == "s", "Subjectivity",
                   if_else(predictor == "pmi", "PMI",
                   if_else(predictor == "ic", "IC",
                   if_else(predictor == "ig", "IG", "ERROR"))))) %>%
  mutate(source_n=if_else(source_n == "ncl", "Nouns: Clusters", "Nouns: Wordforms"),
         source_a=if_else(source_a == "acl", "Adjectives: Clusters", "Adjectives: Wordforms")) %>%
  mutate(source_n=factor(source_n, levels=c("Nouns: Wordforms", "Nouns: Clusters")),
         source_a=factor(source_a, levels=c("Adjectives: Wordforms", "Adjectives: Clusters"))) %>%
  ggplot(aes(x=predictor, y=m, ymin=lower, ymax=upper, fill=predictor)) +     
    geom_bar(stat="identity") +
    geom_errorbar(width=.2) + 
    facet_grid(source_n~source_a) +
    theme_bw() +
    ylim(0, 1) + 
    ylab("accuracy")
}


```

```{r}
plot_accuracies(PREDICTORS, train_d, ud_test_d)
```

```{r}
plot_accuracies(PREDICTORS, train_d, cc_test_d)
```


```{r}
get_accuracy_table(VS_SUBJECTIVITY_WF, train_d, cc_test_d) %>% arrange(-m)
```

```{r}
get_accuracy_table(VS_SUBJECTIVITY_WF, train_d, cc_test_d) %>% arrange(-m)
```

```{r}
get_accuracy_table(THREE, train_d, ud_test_d) %>% arrange(-m)
```

```{r}
get_accuracy_table(VS_SUBJECTIVITY_WF, train_d, ud_test_d) %>% arrange(-m)
```


```{r}
get_accuracy_table(THREE, train_d, cc_test_d) %>% arrange(-m)
```

## Qualitative analysis

```{r}

populate_predictions = function(train_d, test_d) {
  d = test_d 
  for (predictor in PREDICTORS) {
    predictions = get_predictions(predictor, train_d, test_d)
    d[,predictor] = predictions
  }
  d
}
populate_corrects = function(train_d, test_d) {
  d = test_d 
  for (predictor in PREDICTORS) {
    corrects = get_corrects(predictor, train_d, test_d)
    d[,predictor] = corrects
  }
  d
}

overlap = function(xs, ys) {
  stopifnot(length(xs) == length(ys))
  sum(xs == ys, na.rm=T) / sum(!is.na(xs))
}

predictions_ud = populate_predictions(train_d, ud_test_d)
corrects_ud = populate_corrects(train_d, ud_test_d)

predictions_cc = populate_predictions(train_d, cc_test_d)
corrects_cc = populate_corrects(train_d, cc_test_d)


filter(corrects_ud, pmi_awf_nwf & !s_awf)


```
```{r}
filter(corrects_ud, !pmi_awf_nwf & s_awf)
```



```{r}
filter(corrects_ud, !pmi_awf_nwf & ic_acl_ncl & !s_awf)
```

```{r}
filter(corrects_ud, ig_acl_ncl & !ic_acl_ncl & !pmi_awf_nwf)
```

```{r}
filter(d, !pmi_awf_nwf & s_awf)

```

```{r}
filter(d, ic_acl_ncl & !pmi_awf_nwf)

```

## How much do predictions overlap? 

```{r}
num_predictors = length(PREDICTORS)
crossed = data.frame(p1=rep(PREDICTORS, each=num_predictors), p2=rep(PREDICTORS, times=num_predictors))
crossed$overlap = NA
for(row in 1:nrow(crossed)) {
  p1 = crossed[row,"p1"]
  p2 = crossed[row,"p2"]
  crossed[row,]$overlap = overlap(predictions_ud[p1,], predictions_ud[p2,])
}

ggplot(crossed, aes(x=p1, y=p2, fill=overlap)) + geom_tile()
```


```{r}
to_compare = c("pmi_awf_nwf", "s_awf", "ic_awf_nwf", "ig_awf_nwf")

crossed %>%
  filter(p1 %in% to_compare, p2 %in% to_compare) %>%
  ggplot(aes(x=p1, y=p2, fill=overlap)) + geom_tile()
```

```{r}
to_compare = c("pmi_acl_ncl", "s_acl", "ic_acl_ncl", "ig_acl_ncl")

crossed %>%
  filter(p1 %in% to_compare, p2 %in% to_compare) %>%
  ggplot(aes(x=p1, y=p2, fill=overlap)) + geom_tile()
```

```{r}
to_compare = c("pmi_awf_nwf", "s_awf", "ic_awf_nwf", "ig_awf_nwf", "pmi_acl_ncl", "s_acl", "ic_acl_ncl", "ig_acl_ncl")

crossed %>%
  filter(p1 %in% to_compare, p2 %in% to_compare) %>%
  ggplot(aes(x=p1, y=p2, fill=overlap)) + geom_tile()
```

## AUC

```{r}


  
```
  